{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnn\\AppData\\Local\\Temp\\ipykernel_7468\\4221061706.py:16: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from tensorflow.python.client import device_lib\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from weight_tuning import WeightTuning\n",
    "\n",
    "# model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(8, activation='relu',kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.1),\n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax',kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.1))\n",
    "])\n",
    "\n",
    "\n",
    "# load and preprocess dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight tuning EB_LG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.3186 - accuracy: 0.9103 - 910ms/epoch - 3ms/step\n",
      "Test accuracy: 0.9103000164031982\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# initialize weight tuning object\n",
    "weight_tuning = WeightTuning(learning_rate=0.01)\n",
    "\n",
    "# train model using weight tuning\n",
    "weight_tuning.update_weights_EB_LG(model, x_train, y_train, num_epochs=200, batch_size=64,category_threshold=7)\n",
    "\n",
    "# evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight tuning LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.3539 - accuracy: 0.8987 - 560ms/epoch - 2ms/step\n",
      "Test accuracy: 0.8986999988555908\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# initialize weight tuning object\n",
    "weight_tuning = WeightTuning(learning_rate=0.01)\n",
    "\n",
    "# train model using weight tuning\n",
    "weight_tuning.update_weights_LG(model, x_train, y_train, category_threshold=7)\n",
    "\n",
    "# evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmark(weight tuning_EB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.2675 - accuracy: 0.9279 - 816ms/epoch - 3ms/step\n",
      "Test accuracy: 0.9279000163078308\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# initialize weight tuning object\n",
    "weight_tuning = WeightTuning(learning_rate=0.01)\n",
    "\n",
    "# train model using weight tuning\n",
    "weight_tuning.update_weights_EB(model, x_train, y_train,num_epochs=200,batch_size=64)\n",
    "\n",
    "# evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.3_py_3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04ef98aeeb2e53462cc1fb615d21d9d2583ce764928302fcb73a14ea9aa6239f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
