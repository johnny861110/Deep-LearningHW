{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c636d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "print(\"TensorFlow version:\",tf.__version__)\n",
    "import numpy as np\n",
    "from kerastuner.tuners import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735f567e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BayesianOptimization in module keras_tuner.tuners.bayesian:\n",
      "\n",
      "class BayesianOptimization(keras_tuner.engine.tuner.Tuner)\n",
      " |  BayesianOptimization(hypermodel=None, objective=None, max_trials=10, num_initial_points=None, alpha=0.0001, beta=2.6, seed=None, hyperparameters=None, tune_new_entries=True, allow_new_entries=True, max_retries_per_trial=0, max_consecutive_failed_trials=3, **kwargs)\n",
      " |  \n",
      " |  BayesianOptimization tuning with Gaussian process.\n",
      " |  \n",
      " |  Args:\n",
      " |      hypermodel: Instance of `HyperModel` class (or callable that takes\n",
      " |          hyperparameters and returns a `Model` instance). It is optional\n",
      " |          when `Tuner.run_trial()` is overriden and does not use\n",
      " |          `self.hypermodel`.\n",
      " |      objective: A string, `keras_tuner.Objective` instance, or a list of\n",
      " |          `keras_tuner.Objective`s and strings. If a string, the direction of\n",
      " |          the optimization (min or max) will be inferred. If a list of\n",
      " |          `keras_tuner.Objective`, we will minimize the sum of all the\n",
      " |          objectives to minimize subtracting the sum of all the objectives to\n",
      " |          maximize. The `objective` argument is optional when\n",
      " |          `Tuner.run_trial()` or `HyperModel.fit()` returns a single float as\n",
      " |          the objective to minimize.\n",
      " |      max_trials: Integer, the total number of trials (model configurations)\n",
      " |          to test at most. Note that the oracle may interrupt the search\n",
      " |          before `max_trial` models have been tested if the search space has\n",
      " |          been exhausted. Defaults to 10.\n",
      " |      num_initial_points: Optional number of randomly generated samples as\n",
      " |          initial training data for Bayesian optimization. If left\n",
      " |          unspecified, a value of 3 times the dimensionality of the\n",
      " |          hyperparameter space is used.\n",
      " |      alpha: Float, the value added to the diagonal of the kernel matrix\n",
      " |          during fitting. It represents the expected amount of noise in the\n",
      " |          observed performances in Bayesian optimization. Defaults to 1e-4.\n",
      " |      beta: Float, the balancing factor of exploration and exploitation. The\n",
      " |          larger it is, the more explorative it is. Defaults to 2.6.\n",
      " |      seed: Optional integer, the random seed.\n",
      " |      hyperparameters: Optional `HyperParameters` instance. Can be used to\n",
      " |          override (or register in advance) hyperparameters in the search\n",
      " |          space.\n",
      " |      tune_new_entries: Boolean, whether hyperparameter entries that are\n",
      " |          requested by the hypermodel but that were not specified in\n",
      " |          `hyperparameters` should be added to the search space, or not. If\n",
      " |          not, then the default value for these parameters will be used.\n",
      " |          Defaults to True.\n",
      " |      allow_new_entries: Boolean, whether the hypermodel is allowed to\n",
      " |          request hyperparameter entries not listed in `hyperparameters`.\n",
      " |          Defaults to True.\n",
      " |      max_retries_per_trial: Integer. Defaults to 0. The maximum number of\n",
      " |          times to retry a `Trial` if the trial crashed or the results are\n",
      " |          invalid.\n",
      " |      max_consecutive_failed_trials: Integer. Defaults to 3. The maximum\n",
      " |          number of consecutive failed `Trial`s. When this number is reached,\n",
      " |          the search will be stopped. A `Trial` is marked as failed when none\n",
      " |          of the retries succeeded.\n",
      " |      **kwargs: Keyword arguments relevant to all `Tuner` subclasses. Please\n",
      " |          see the docstring for `Tuner`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BayesianOptimization\n",
      " |      keras_tuner.engine.tuner.Tuner\n",
      " |      keras_tuner.engine.base_tuner.BaseTuner\n",
      " |      keras_tuner.engine.stateful.Stateful\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hypermodel=None, objective=None, max_trials=10, num_initial_points=None, alpha=0.0001, beta=2.6, seed=None, hyperparameters=None, tune_new_entries=True, allow_new_entries=True, max_retries_per_trial=0, max_consecutive_failed_trials=3, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras_tuner.engine.tuner.Tuner:\n",
      " |  \n",
      " |  get_best_models(self, num_models=1)\n",
      " |      Returns the best model(s), as determined by the tuner's objective.\n",
      " |      \n",
      " |      The models are loaded with the weights corresponding to\n",
      " |      their best checkpoint (at the end of the best epoch of best trial).\n",
      " |      \n",
      " |      This method is for querying the models trained during the search.\n",
      " |      For best performance, it is recommended to retrain your Model on the\n",
      " |      full dataset using the best hyperparameters found during `search`,\n",
      " |      which can be obtained using `tuner.get_best_hyperparameters()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_models: Optional number of best models to return.\n",
      " |              Defaults to 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of trained model instances sorted from the best to the worst.\n",
      " |  \n",
      " |  load_model(self, trial)\n",
      " |      Loads a Model from a given trial.\n",
      " |      \n",
      " |      For models that report intermediate results to the `Oracle`, generally\n",
      " |      `load_model` should load the best reported `step` by relying of\n",
      " |      `trial.best_step`.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance, the `Trial` corresponding to the model\n",
      " |              to load.\n",
      " |  \n",
      " |  on_batch_begin(self, trial, model, batch, logs)\n",
      " |      Called at the beginning of a batch.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |          model: A Keras `Model`.\n",
      " |          batch: The current batch number within the current epoch.\n",
      " |          logs: Additional metrics.\n",
      " |  \n",
      " |  on_batch_end(self, trial, model, batch, logs=None)\n",
      " |      Called at the end of a batch.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |          model: A Keras `Model`.\n",
      " |          batch: The current batch number within the current epoch.\n",
      " |          logs: Additional metrics.\n",
      " |  \n",
      " |  on_epoch_begin(self, trial, model, epoch, logs=None)\n",
      " |      Called at the beginning of an epoch.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |          model: A Keras `Model`.\n",
      " |          epoch: The current epoch number.\n",
      " |          logs: Additional metrics.\n",
      " |  \n",
      " |  on_epoch_end(self, trial, model, epoch, logs=None)\n",
      " |      Called at the end of an epoch.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |          model: A Keras `Model`.\n",
      " |          epoch: The current epoch number.\n",
      " |          logs: Dict. Metrics for this epoch. This should include\n",
      " |            the value of the objective for this epoch.\n",
      " |  \n",
      " |  run_trial(self, trial, *args, **kwargs)\n",
      " |      Evaluates a set of hyperparameter values.\n",
      " |      \n",
      " |      This method is called multiple times during `search` to build and\n",
      " |      evaluate the models with different hyperparameters and return the\n",
      " |      objective value.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      You can use it with `self.hypermodel` to build and fit the model.\n",
      " |      \n",
      " |      ```python\n",
      " |      def run_trial(self, trial, *args, **kwargs):\n",
      " |          hp = trial.hyperparameters\n",
      " |          model = self.hypermodel.build(hp)\n",
      " |          return self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      " |      ```\n",
      " |      \n",
      " |      You can also use it as a black-box optimizer for anything.\n",
      " |      \n",
      " |      ```python\n",
      " |      def run_trial(self, trial, *args, **kwargs):\n",
      " |          hp = trial.hyperparameters\n",
      " |          x = hp.Float(\"x\", -2.0, 2.0)\n",
      " |          y = x * x + 2 * x + 1\n",
      " |          return y\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance that contains the information needed to\n",
      " |              run this trial. Hyperparameters can be accessed via\n",
      " |              `trial.hyperparameters`.\n",
      " |          *args: Positional arguments passed by `search`.\n",
      " |          **kwargs: Keyword arguments passed by `search`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object, which is the return value of `model.fit()`, a\n",
      " |          dictionary, a float, or a list of one of these types.\n",
      " |      \n",
      " |          If return a dictionary, it should be a dictionary of the metrics to\n",
      " |          track. The keys are the metric names, which contains the\n",
      " |          `objective` name. The values should be the metric values.\n",
      " |      \n",
      " |          If return a float, it should be the `objective` value.\n",
      " |      \n",
      " |          If evaluating the model for multiple times, you may return a list\n",
      " |          of results of any of the types above. The final objective value is\n",
      " |          the average of the results in the list.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras_tuner.engine.base_tuner.BaseTuner:\n",
      " |  \n",
      " |  get_best_hyperparameters(self, num_trials=1)\n",
      " |      Returns the best hyperparameters, as determined by the objective.\n",
      " |      \n",
      " |      This method can be used to reinstantiate the (untrained) best model\n",
      " |      found during the search process.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      best_hp = tuner.get_best_hyperparameters()[0]\n",
      " |      model = tuner.hypermodel.build(best_hp)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          num_trials: Optional number of `HyperParameters` objects to return.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of `HyperParameter` objects sorted from the best to the worst.\n",
      " |  \n",
      " |  get_state(self)\n",
      " |      Returns the current state of this object.\n",
      " |      \n",
      " |      This method is called during `save`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of serializable objects as the state.\n",
      " |  \n",
      " |  get_trial_dir(self, trial_id)\n",
      " |  \n",
      " |  on_search_begin(self)\n",
      " |      Called at the beginning of the `search` method.\n",
      " |  \n",
      " |  on_search_end(self)\n",
      " |      Called at the end of the `search` method.\n",
      " |  \n",
      " |  on_trial_begin(self, trial)\n",
      " |      Called at the beginning of a trial.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |  \n",
      " |  on_trial_end(self, trial)\n",
      " |      Called at the end of a trial.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial: A `Trial` instance.\n",
      " |  \n",
      " |  pre_create_trial(self)\n",
      " |      Called before self.oracle.create_trial and before on_trial_begin.\n",
      " |  \n",
      " |  reload(self)\n",
      " |      Reloads this object from its project directory.\n",
      " |  \n",
      " |  results_summary(self, num_trials=10)\n",
      " |      Display tuning results summary.\n",
      " |      \n",
      " |      The method prints a summary of the search results including the\n",
      " |      hyperparameter values and evaluation results for each trial.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_trials: Optional number of trials to display. Defaults to 10.\n",
      " |  \n",
      " |  save(self)\n",
      " |      Saves this object to its project directory.\n",
      " |  \n",
      " |  save_model(self, trial_id, model, step=0)\n",
      " |      Saves a Model for a given trial.\n",
      " |      \n",
      " |      Args:\n",
      " |          trial_id: The ID of the `Trial` corresponding to this Model.\n",
      " |          model: The trained model.\n",
      " |          step: Integer, for models that report intermediate results to the\n",
      " |              `Oracle`, the step the saved file correspond to. For example,\n",
      " |              for Keras models this is the number of epochs trained.\n",
      " |  \n",
      " |  search(self, *fit_args, **fit_kwargs)\n",
      " |      Performs a search for best hyperparameter configuations.\n",
      " |      \n",
      " |      Args:\n",
      " |          *fit_args: Positional arguments that should be passed to\n",
      " |            `run_trial`, for example the training and validation data.\n",
      " |          **fit_kwargs: Keyword arguments that should be passed to\n",
      " |            `run_trial`, for example the training and validation data.\n",
      " |  \n",
      " |  search_space_summary(self, extended=False)\n",
      " |      Print search space summary.\n",
      " |      \n",
      " |      The methods prints a summary of the hyperparameters in the search\n",
      " |      space, which can be called before calling the `search` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          extended: Optional boolean, whether to display an extended summary.\n",
      " |              Defaults to False.\n",
      " |  \n",
      " |  set_state(self, state)\n",
      " |      Sets the current state of this object.\n",
      " |      \n",
      " |      This method is called during `reload`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state: A dictionary of serialized objects as the state to restore.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras_tuner.engine.base_tuner.BaseTuner:\n",
      " |  \n",
      " |  project_dir\n",
      " |  \n",
      " |  remaining_trials\n",
      " |      Returns the number of trials remaining.\n",
      " |      \n",
      " |      Will return `None` if `max_trials` is not set. This is useful when\n",
      " |      resuming a previously stopped search.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras_tuner.engine.stateful.Stateful:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BayesianOptimization)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c5f56fb",
   "metadata": {},
   "source": [
    "### Test envirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c4a5830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dfe9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3044278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17840601757068976658\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3643801600\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1043382118857638562\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a201f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(5);\n",
    "a = tf.random.normal([10000,2], 0, 1, tf.float32, seed=1)\n",
    "b = tf.random.normal([2,10000], 0, 1, tf.float32, seed=1)\n",
    "c = tf.matmul(a, b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7a64a95",
   "metadata": {},
   "source": [
    "### Model Construct"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4f28853c",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bcc49ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_builder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mHyperband(model_builder,\n\u001b[0;32m      2\u001b[0m                      objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                      max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m      4\u001b[0m                      factor\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m      5\u001b[0m                      directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmy_dir\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                      project_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mintro_to_kt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_builder' is not defined"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "c:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "activation_fn = ['tanh','relu']\n",
    "hidden_node = [5,8,11]\n",
    "init_weight = ['small random number','Xavier','Kaiming','MSRA']\n",
    "optimizer_type = [SGD(lr=0.01), SGD(lr=0.01, momentum=0.9), Adam(lr=0.01)]\n",
    "learning_epochs = [100,200,300]\n",
    "learning_decay_schedule = ['none','cosine']\n",
    "loss_functions = ['categorical_crossentropy', 'mean_squared_error']\n",
    "regularization_coefficients = [0.001, 0.0001]\n",
    "num_class = 10\n",
    "data_preprocessing = True\n",
    "num_ensembles = 3\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12783885",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109dd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model ):\n",
    "    def __init__(self,activation_fn,hidden_node,init_weight,\n",
    "                 optimizer_type,regularization_coefficients,\n",
    "                 num_class):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "        self.hidden_node = hidden_node\n",
    "        self.init_weight = init_weight\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.regularizaton_coefficients = regularization_coefficients\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        out = self.flatten_layer(inputs)\n",
    "        out = self.hidden_layer(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "    \n",
    "def model_build(hp):\n",
    "    activation_fn = hp.Choice('activation_fn',values = ['tanh','relu'])\n",
    "    hidden_node = hp.Choice('hidden_node',values = [5,8,11])\n",
    "    init_weight = hp.Choice('init_weight',values = ['random_normal','glorot_uniform','he_uniform'])\n",
    "    optimizer_type = hp.Choice('optimizer_type',values = ['SGD', 'Adam', 'Momenton'] )\n",
    "    regularization_coefficients = hp.Choice()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231860e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[39m=\u001b[39m MyModel\u001b[39m.\u001b[39mfit(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "a = MyModel.fit(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "004670d6",
   "metadata": {},
   "source": [
    "### Create a TensorFlow device context to use a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected.\")\n",
    "else:\n",
    "    print('GPU Device:', device_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af0323a6",
   "metadata": {},
   "source": [
    "### load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae047e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op OneHot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op OneHot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DummySeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DummySeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'activation_functions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m test_dataset \u001b[39m=\u001b[39m test_dataset\u001b[39m.\u001b[39mbatch(BATCH_SIZE)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Train the neural network using different hyperparameter settings\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfor\u001b[39;00m activation_function \u001b[39min\u001b[39;00m activation_functions:\n\u001b[0;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m weight_initializer \u001b[39min\u001b[39;00m weight_initializers:\n\u001b[0;32m     29\u001b[0m         \u001b[39mfor\u001b[39;00m loss_function \u001b[39min\u001b[39;00m loss_functions:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'activation_functions' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device(device_name):\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Preprocess the data(N:normalize)\n",
    "    x_train_N = x_train.astype('float32') / 255.0\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test_N = x_test.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train_N = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test_N = x_test.reshape(x_test.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "    y_train = tf.one_hot(y_train, depth=10)\n",
    "    y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    BATCH_SIZE = 64\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "    train_N_dataset = tf.data.Dataset.from_tensor_slices((x_train_N, y_train))\n",
    "    train_N_dataset = train_N_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    \n",
    "    # Train the neural network using different hyperparameter settings\n",
    "    for activation_function in activation_fn:\n",
    "        for weight_initializer in init_weight:\n",
    "            for loss_function in loss_functions:\n",
    "                for regularization_coefficient in regularization_coefficients:\n",
    "                    for optimizer in optimizer_type:\n",
    "                        for learning_epoch in learning_epochs:\n",
    "                            for hidden_nodes in hidden_node:\n",
    "                                for learning_rate_decay_schedule in learning_rate_decay_schedules:\n",
    "                                    print(\"Training model with activation function {}, weight initializer {}, loss function {}, regularization coefficient {}, optimizer {}, num epochs {}, num hidden nodes {}, learning rate decay schedule {}\".format(\n",
    "                                        activation_function, weight_initializer, loss_function, regularization_coefficient, optimizer.__class__.__name__, learning_epoch, hidden_nodes, learning_rate_decay_schedule))\n",
    "                                    val_accs = []\n",
    "                                    for ensemble_idx in range(num_ensembles):\n",
    "                                        # Build the model\n",
    "                                        model = build_model(num_hidden_nodes=hidden_nodes, activation_function=activation_function, weight_initializer=weight_initializer, loss_function=loss_function, regularization_coefficient=regularization_coefficient, optimizer=optimizer)\n",
    "                                        \n",
    "                                        # Define the learning rate decay schedule\n",
    "                                        if learning_rate_decay_schedule is not None:\n",
    "                                            if learning_rate_decay_schedule == 'cosine':\n",
    "                                                def cosine_decay(epoch):\n",
    "                                                    return 0.5 * (1 + np.cos((epoch * np.pi) / learning_epoch))\n",
    "                                                lr_scheduler = LearningRateScheduler(cosine_decay)\n",
    "                                            else:\n",
    "                                                raise ValueError(\"Unknown learning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "x_train_normal = x_train.astype('float32') / 255.0\n",
    "x_test_normal = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e05a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and optimizer\n",
    "    model = MyModel()\n",
    "    optimizer_adam = tf.keras.optimizers.Adam()\n",
    "    optimizer_sdg = tf.keras.optimizers.SGD()\n",
    "    optimizer_momenton = tf.keras.optimizers.SGD(momentum=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a22af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GradientTape' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m gradients \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mGradientTape(loss_value, model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m     70\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39;49m(gradients, model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[0;32m     72\u001b[0m \u001b[39m# Update metrics\u001b[39;00m\n\u001b[0;32m     73\u001b[0m epoch_loss_avg\u001b[39m.\u001b[39mupdate_state(loss_value)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'GradientTape' object is not iterable"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.reshape(x_train.shape[0], 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], 784).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.1\n",
    "num_epochs = 300\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 11\n",
    "reg_lambda = 0.001\n",
    "activation_fn = tf.nn.relu\n",
    "weight_initializer = tf.initializers.GlorotUniform()\n",
    "\n",
    "# Define model\n",
    "class TwoLayerNN(tf.keras.Model):\n",
    "    def __init__(self, num_hidden_nodes):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(num_hidden_nodes, activation=activation_fn,\n",
    "                                            kernel_initializer=weight_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(10, kernel_initializer=weight_initializer)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Create model instance\n",
    "model = TwoLayerNN(num_hidden_nodes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Define train and test datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Training loop\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "test_loss_results = []\n",
    "test_accuracy_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    for x, y in train_dataset:\n",
    "        with tf.device('/GPU:0'): # Use GPU for training\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y, logits)\n",
    "            # Add regularization term to loss\n",
    "            l2_loss = sum(model.losses)\n",
    "            loss_value += reg_lambda * l2_loss\n",
    "            # Compute gradients\n",
    "            gradients = tf.GradientTape(loss_value, model.trainable_variables)\n",
    "            # Update weights\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            # Update metrics\n",
    "            epoch_loss_avg.update_state(loss_value)\n",
    "            epoch_accuracy.update_state(y, logits)\n",
    "    \n",
    "    # Save results for current epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    # Testing\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    for x, y in test_dataset:\n",
    "        with tf.device('/GPU:0'): # Use GPU for testing\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y, logits)\n",
    "            # Add regularization term to loss\n",
    "            l2_loss = sum(model.losses)\n",
    "            loss_value += reg_lambda * l2_loss\n",
    "            # Update metrics\n",
    "            epoch_loss_avg.update_state(loss_value)\n",
    "            epoch_accuracy.update_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e849339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_bulid import MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb13d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MyModel in module model_bulid:\n",
      "\n",
      "class MyModel(keras.engine.training.Model)\n",
      " |  MyModel(activation_fn, hidden_node, init_weight, optimizer_type, regularization_coefficients, num_class)\n",
      " |  \n",
      " |  #construct model stucture\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MyModel\n",
      " |      keras.engine.training.Model\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, activation_fn, hidden_node, init_weight, optimizer_type, regularization_coefficients, num_class)\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      Calls the model on new inputs and returns the outputs as tensors.\n",
      " |      \n",
      " |      In this case `call()` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Note: This method should not be called directly. It is only meant to be\n",
      " |      overridden when subclassing `tf.keras.Model`.\n",
      " |      To call a model on an input, always use the `__call__()` method,\n",
      " |      i.e. `model(inputs)`, which relies on the underlying `call()` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to\n",
      " |            run the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be either a boolean tensor\n",
      " |            or None (no mask). For more details, check the guide\n",
      " |            [here](https://www.tensorflow.org/guide/keras/masking_and_padding).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at\n",
      " |      instantiation time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of\n",
      " |         shapes, where shapes are tuples, integers, or `TensorShape`\n",
      " |         instances.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, `TensorShape`, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or keyword arg in call\n",
      " |             signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling\n",
      " |        it on real tensor data.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
      " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
      " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
      " |                             tf.keras.metrics.FalseNegatives()])\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: Loss function. May be a string (name of loss function), or\n",
      " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where `y_true` are the ground truth values, and\n",
      " |            `y_pred` are the model's predictions.\n",
      " |            `y_true` should have shape\n",
      " |            `(batch_size, d0, .. dN)` (except in the case of\n",
      " |            sparse loss functions such as\n",
      " |            sparse categorical crossentropy which expects integer arrays of\n",
      " |            shape `(batch_size, d0, .. dN-1)`).\n",
      " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      " |            The loss function should return a float tensor.\n",
      " |            If a custom `Loss` instance is\n",
      " |            used and reduction is set to `None`, return value has shape\n",
      " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
      " |            values; otherwise, it is a scalar. If the model has multiple\n",
      " |            outputs, you can use a different loss on each output by passing a\n",
      " |            dictionary or a list of losses. The loss value that will be\n",
      " |            minimized by the model will then be the sum of all individual\n",
      " |            losses, unless `loss_weights` is specified.\n",
      " |          metrics: List of metrics to be evaluated by the model during\n",
      " |            training and testing. Each of this can be a string (name of a\n",
      " |            built-in function), function or a `tf.keras.metrics.Metric`\n",
      " |            instance. See `tf.keras.metrics`. Typically you will use\n",
      " |            `metrics=['accuracy']`.\n",
      " |            A function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |            `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
      " |            You can also pass a list to specify a metric or a list of metrics\n",
      " |            for each output, such as\n",
      " |            `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |            strings 'accuracy' or 'acc', we convert this to one of\n",
      " |            `tf.keras.metrics.BinaryAccuracy`,\n",
      " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |            function used and the model output shape. We do a similar\n",
      " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |            The metrics passed here are evaluated without sample weighting; if\n",
      " |            you would like sample weighting to apply, you can specify your\n",
      " |            metrics via the `weighted_metrics` argument instead.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |            coefficients (Python floats) to weight the loss contributions of\n",
      " |            different model outputs. The loss value that will be minimized by\n",
      " |            the model will then be the *weighted sum* of all individual\n",
      " |            losses, weighted by the `loss_weights` coefficients.  If a list,\n",
      " |            it is expected to have a 1:1 mapping to the model's outputs. If a\n",
      " |            dict, it is expected to map output names (strings) to scalar\n",
      " |            coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            `sample_weight` or `class_weight` during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead. At most, one\n",
      " |            full epoch will be run each execution. If a number larger than the\n",
      " |            size of the epoch is passed, the execution will be truncated to\n",
      " |            the size of the epoch. Note that if `steps_per_execution` is set\n",
      " |            to `N`, `Callback.on_batch_begin` and `Callback.on_batch_end`\n",
      " |            methods will only be called every `N` batches (i.e. before/after\n",
      " |            each `tf.function` execution).\n",
      " |          jit_compile: If `True`, compile the model training step with XLA.\n",
      " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
      " |            for machine learning.\n",
      " |            `jit_compile` is not enabled for by default.\n",
      " |            This option cannot be enabled with `run_eagerly=True`.\n",
      " |            Note that `jit_compile=True`\n",
      " |            may not necessarily work for all models.\n",
      " |            For more information on supported operations please refer to the\n",
      " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
      " |            Also refer to\n",
      " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
      " |            for more details.\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |  \n",
      " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
      " |      Compute the total loss, validate it, and return it.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom loss\n",
      " |      computation logic.\n",
      " |      \n",
      " |      Example:\n",
      " |      ```python\n",
      " |      class MyModel(tf.keras.Model):\n",
      " |      \n",
      " |        def __init__(self, *args, **kwargs):\n",
      " |          super(MyModel, self).__init__(*args, **kwargs)\n",
      " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
      " |      \n",
      " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
      " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
      " |          loss += tf.add_n(self.losses)\n",
      " |          self.loss_tracker.update_state(loss)\n",
      " |          return loss\n",
      " |      \n",
      " |        def reset_metrics(self):\n",
      " |          self.loss_tracker.reset_states()\n",
      " |      \n",
      " |        @property\n",
      " |        def metrics(self):\n",
      " |          return [self.loss_tracker]\n",
      " |      \n",
      " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
      " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
      " |      \n",
      " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
      " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
      " |      model = MyModel(inputs, outputs)\n",
      " |      model.add_loss(tf.reduce_sum(outputs))\n",
      " |      \n",
      " |      optimizer = tf.keras.optimizers.SGD()\n",
      " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
      " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
      " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Input data.\n",
      " |        y: Target data.\n",
      " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
      " |        sample_weight: Sample weights for weighting the loss function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which\n",
      " |        is the case when called by `Model.test_step`).\n",
      " |  \n",
      " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
      " |      Update metric states and collect all metrics to be returned.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom metric\n",
      " |      updating and collection logic.\n",
      " |      \n",
      " |      Example:\n",
      " |      ```python\n",
      " |      class MyModel(tf.keras.Sequential):\n",
      " |      \n",
      " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
      " |      \n",
      " |          # This super call updates `self.compiled_metrics` and returns\n",
      " |          # results for all metrics listed in `self.metrics`.\n",
      " |          metric_results = super(MyModel, self).compute_metrics(\n",
      " |              x, y, y_pred, sample_weight)\n",
      " |      \n",
      " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
      " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
      " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
      " |          return metric_results\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Input data.\n",
      " |        y: Target data.\n",
      " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
      " |        sample_weight: Sample weights for weighting the loss function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
      " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
      " |              targets)` or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator\n",
      " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
      " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |            If `x` is a dataset, generator or `keras.utils.Sequence` instance,\n",
      " |            `y` should not be specified (since targets will be obtained from\n",
      " |            the iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do\n",
      " |            not specify the `batch_size` if your data is in the form of a\n",
      " |            dataset, generators, or `keras.utils.Sequence` instances (since\n",
      " |            they generate batches).\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so `verbose=2` is\n",
      " |              recommended when not running interactively (e.g. in a production\n",
      " |              environment).\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat\n",
      " |            (1D) Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every\n",
      " |                timestep of every sample. This argument is not supported when\n",
      " |                `x` is a dataset, instead pass sample weights as the third\n",
      " |                element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps`\n",
      " |            is None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
      " |            queue. If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using\n",
      " |            process-based threading. If unspecified, `workers` will default to\n",
      " |            1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to\n",
      " |            the generator as they can't be passed easily to children\n",
      " |            processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |            dict, with each key being the name of the metric. If `False`, they\n",
      " |            are returned as a list.\n",
      " |          **kwargs: Unused at this time.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any\n",
      " |        need to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
      " |              targets)` or `(inputs, targets, sample_weights)`.\n",
      " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
      " |              callable that takes a single argument of type\n",
      " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
      " |              `DatasetCreator` should be used when users prefer to specify the\n",
      " |              per-replica batching and sharding logic for the `Dataset`.\n",
      " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
      " |              information.\n",
      " |            A more detailed description of unpacking behavior for iterator\n",
      " |            types (Dataset, generator, Sequence) is given below. If these\n",
      " |            include `sample_weights` as a third component, note that sample\n",
      " |            weighting applies to the `weighted_metrics` argument but not the\n",
      " |            `metrics` argument in `compile()`. If using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
      " |            `DatasetCreator` type is supported for `x`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence`\n",
      " |              instances (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided\n",
      " |              (unless the `steps_per_epoch` flag is set to\n",
      " |              something other than None).\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so verbose=2 is\n",
      " |              recommended when not running interactively (eg, in a production\n",
      " |              environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note\n",
      " |              `tf.keras.callbacks.ProgbarLogger` and\n",
      " |              `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |              Callbacks with batch-level calls are currently unsupported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`, and users\n",
      " |              are advised to implement epoch-level calls instead with an\n",
      " |              appropriate `steps_per_epoch` value.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This\n",
      " |              argument is not supported when `x` is a dataset, generator or\n",
      " |              `keras.utils.Sequence` instance.\n",
      " |              If both `validation_data` and `validation_split` are provided,\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_split` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using\n",
      " |              `validation_split` or `validation_data` is not affected by\n",
      " |              regularization layers like noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
      " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      " |                  arrays.\n",
      " |                - A `tf.data.Dataset`.\n",
      " |                - A Python generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      " |              `validation_data` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is\n",
      " |              ignored when `x` is a generator or an object of tf.data.Dataset.\n",
      " |              'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              This argument is not supported when `x` is a dataset, generator,\n",
      " |              or `keras.utils.Sequence` instance, instead provide the\n",
      " |              sample_weights as the third element of `x`.\n",
      " |              Note that sample weighting does not apply to metrics specified\n",
      " |              via the `metrics` argument in `compile()`. To apply sample\n",
      " |              weighting to your metrics, you can specify them via the\n",
      " |              `weighted_metrics` in `compile()` instead.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is\n",
      " |              exhausted.  When passing an infinitely repeating dataset, you\n",
      " |              must specify the `steps_per_epoch` argument. If\n",
      " |              `steps_per_epoch=-1` the training will run indefinitely with an\n",
      " |              infinitely repeating dataset.  This argument is not supported\n",
      " |              with array inputs.\n",
      " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
      " |                * `steps_per_epoch=None` is not supported.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None,\n",
      " |              validation will run until the `validation_data` dataset is\n",
      " |              exhausted. In the case of an infinitely repeated dataset, it\n",
      " |              will run into an infinite loop. If 'validation_steps' is\n",
      " |              specified and only part of the dataset will be consumed, the\n",
      " |              evaluation will start from the beginning of the dataset at each\n",
      " |              epoch. This ensures that the same validation samples are used\n",
      " |              every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in\n",
      " |              the form of datasets, generators, or `keras.utils.Sequence`\n",
      " |              instances (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided.\n",
      " |            Integer or `collections.abc.Container` instance (e.g. list, tuple,\n",
      " |            etc.).  If an integer, specifies how many training epochs to run\n",
      " |            before a new validation run is performed, e.g. `validation_freq=2`\n",
      " |            runs validation every 2 epochs. If a Container, specifies the\n",
      " |            epochs on which to run validation, e.g.\n",
      " |            `validation_freq=[1, 2, 10]` runs validation at the end of the\n",
      " |            1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
      " |            queue.  If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children\n",
      " |              processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample\n",
      " |        weights.  Keras requires that the output of such iterator-likes be\n",
      " |        unambiguous. The iterator should return a tuple of length 1, 2, or 3,\n",
      " |        where the optional second and third elements will be used for y and\n",
      " |        sample_weight respectively. Any other type provided will be wrapped in\n",
      " |        a length one tuple, effectively treating everything as 'x'. When\n",
      " |        yielding dicts, they should still adhere to the top-level tuple\n",
      " |        structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is\n",
      " |        that it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x,\n",
      " |        y, and sample_weight or passed through as a single element to `x`. As\n",
      " |        a result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the\n",
      " |        issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to\n",
      " |        use this endpoint.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the `Model`.\n",
      " |      \n",
      " |      Config is a Python dictionary (serializable) containing the\n",
      " |      configuration of an object, which in this case is a `Model`. This allows\n",
      " |      the `Model` to be be reinstantiated later (without its trained weights)\n",
      " |      from this configuration.\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Developers of subclassed `Model` are advised to override this method,\n",
      " |      and continue to update the dict from `super(MyModel, self).get_config()`\n",
      " |      to provide the proper configuration of this `Model`. The default config\n",
      " |      is an empty dict. Optionally, raise `NotImplementedError` to allow Keras\n",
      " |      to attempt a default serialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary containing the configuration of this `Model`.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  get_weight_paths(self)\n",
      " |      Retrieve all the variables and their paths for the model.\n",
      " |      \n",
      " |      The variable path (string) is a stable key to indentify a `tf.Variable`\n",
      " |      instance owned by the model. It can be used to specify variable-specific\n",
      " |      configurations (e.g. DTensor, quantization) from a global view.\n",
      " |      \n",
      " |      This method returns a dict with weight object paths as keys\n",
      " |      and the corresponding `tf.Variable` instances as values.\n",
      " |      \n",
      " |      Note that if the model is a subclassed model and the weights haven't\n",
      " |      been initialized, an empty dict will be returned.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict where keys are variable paths and values are `tf.Variable`\n",
      " |           instances.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class SubclassModel(tf.keras.Model):\n",
      " |      \n",
      " |        def __init__(self, name=None):\n",
      " |          super().__init__(name=name)\n",
      " |          self.d1 = tf.keras.layers.Dense(10)\n",
      " |          self.d2 = tf.keras.layers.Dense(20)\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          x = self.d1(inputs)\n",
      " |          return self.d2(x)\n",
      " |      \n",
      " |      model = SubclassModel()\n",
      " |      model(tf.zeros((10, 10)))\n",
      " |      weight_paths = model.get_weight_paths()\n",
      " |      # weight_paths:\n",
      " |      # {\n",
      " |      #    'd1.kernel': model.d1.kernel,\n",
      " |      #    'd1.bias': model.d1.bias,\n",
      " |      #    'd2.kernel': model.d2.kernel,\n",
      " |      #    'd2.bias': model.d2.bias,\n",
      " |      # }\n",
      " |      \n",
      " |      # Functional model\n",
      " |      inputs = tf.keras.Input((10,), batch_size=10)\n",
      " |      x = tf.keras.layers.Dense(20, name='d1')(inputs)\n",
      " |      output = tf.keras.layers.Dense(30, name='d2')(x)\n",
      " |      model = tf.keras.Model(inputs, output)\n",
      " |      d1 = model.layers[1]\n",
      " |      d2 = model.layers[2]\n",
      " |      weight_paths = model.get_weight_paths()\n",
      " |      # weight_paths:\n",
      " |      # {\n",
      " |      #    'd1.kernel': d1.kernel,\n",
      " |      #    'd1.bias': d1.bias,\n",
      " |      #    'd2.kernel': d2.kernel,\n",
      " |      #    'd2.bias': d2.bias,\n",
      " |      # }\n",
      " |      ```\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the\n",
      " |      weights were saved.  Note that layers that don't have weights are not\n",
      " |      taken into account in the topological ordering, so adding or removing\n",
      " |      layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share\n",
      " |      the same name. This is useful for fine-tuning or transfer-learning\n",
      " |      models where some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading\n",
      " |      weights from the TensorFlow format. Note that topological loading\n",
      " |      differs slightly between TensorFlow and HDF5 formats for user-defined\n",
      " |      classes inheriting from `tf.keras.Model`: HDF5 loads based on a\n",
      " |      flattened list of weights, while the TensorFlow format loads based on\n",
      " |      the object-local names of attributes to which layers are assigned in the\n",
      " |      `Model`'s constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, path to the weights file to load. For weight files\n",
      " |              in TensorFlow format, this is the file prefix (the same as was\n",
      " |              passed to `save_weights`). This can also be a path to a\n",
      " |              SavedModel saved from `model.save`.\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where\n",
      " |              there is a mismatch in the number of weights, or a mismatch in\n",
      " |              the shape of the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same\n",
      " |          status object as `tf.train.Checkpoint.restore`. When graph building,\n",
      " |          restore ops are run automatically as soon as the network is built\n",
      " |          (on first call for user-defined classes inheriting from `Model`,\n",
      " |          immediately if it is already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If `h5py` is not available and the weight file is in\n",
      " |            HDF5 format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self, force=False)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the predict function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self, force=False)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the test function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self, force=False)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called. You can skip the cache and generate again the\n",
      " |      function with `force=True`.\n",
      " |      \n",
      " |      Args:\n",
      " |        force: Whether to regenerate the train function and skip the cached\n",
      " |          function if available.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for batch\n",
      " |      processing of large numbers of inputs. It is not intended for use inside\n",
      " |      of loops that iterate over your data and process small numbers of inputs\n",
      " |      at a time.\n",
      " |      \n",
      " |      For small numbers of inputs that fit in one batch,\n",
      " |      directly use `__call__()` for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
      " |      inference. You may pair the individual model call with a `tf.function`\n",
      " |      for additional performance inside your inner loop.\n",
      " |      If you need access to numpy array values instead of tensors after your\n",
      " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
      " |      an eager tensor.\n",
      " |      \n",
      " |      Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Note: See [this FAQ entry](\n",
      " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
      " |      for more details about the difference between `Model` methods\n",
      " |      `predict()` and `__call__()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator\n",
      " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
      " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so `verbose=2` is\n",
      " |              recommended when not running interactively (e.g. in a production\n",
      " |              environment).\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict()` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. Maximum size for the\n",
      " |              generator queue. If unspecified, `max_queue_size` will default\n",
      " |              to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children\n",
      " |              processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules\n",
      " |      as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for\n",
      " |      all three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any\n",
      " |        need to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in a\n",
      " |            `tf.function`.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of\n",
      " |      inference.  This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
      " |      and `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](\n",
      " |      https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save\n",
      " |              the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF\n",
      " |              2.X, and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to\n",
      " |              the 'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are\n",
      " |              stored.  Defaults to `True`. Disabling this will decrease\n",
      " |              serialization time and reduce file size, but it requires that\n",
      " |              all custom layers/models implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_spec(self, dynamic_batch=True)\n",
      " |      Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n",
      " |      \n",
      " |      This value is automatically defined after calling the model for the\n",
      " |      first time. Afterwards, you can use it when exporting the model for\n",
      " |      serving:\n",
      " |      \n",
      " |      ```python\n",
      " |      model = tf.keras.Model(...)\n",
      " |      \n",
      " |      @tf.function\n",
      " |      def serve(*args, **kwargs):\n",
      " |        outputs = model(*args, **kwargs)\n",
      " |        # Apply postprocessing steps, or add additional outputs.\n",
      " |        ...\n",
      " |        return outputs\n",
      " |      \n",
      " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this\n",
      " |      # example, is an empty dict since functional models do not use keyword\n",
      " |      # arguments.\n",
      " |      arg_specs, kwarg_specs = model.save_spec()\n",
      " |      \n",
      " |      model.save(path, signatures={\n",
      " |        'serving_default': serve.get_concrete_function(*arg_specs,\n",
      " |                                                       **kwarg_specs)\n",
      " |      })\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
      " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
      " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
      " |          batch size will always be preserved). Defaults to `True`.\n",
      " |      Returns:\n",
      " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
      " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
      " |        If the model inputs are not defined, returns `None`.\n",
      " |        The model inputs are automatically set when calling the model,\n",
      " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network\n",
      " |      are saved in the same format as `tf.train.Checkpoint`, including any\n",
      " |      `Layer` instances or `Optimizer` instances assigned to object\n",
      " |      attributes. For networks constructed from inputs and outputs using\n",
      " |      `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network\n",
      " |      are tracked/saved automatically. For user-defined classes which inherit\n",
      " |      from `tf.keras.Model`, `Layer` instances must be assigned to object\n",
      " |      attributes, typically in the constructor. See the documentation of\n",
      " |      `tf.train.Checkpoint` and `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should\n",
      " |      be loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a\n",
      " |      root object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save`\n",
      " |      this is the `Checkpoint` even if the `Checkpoint` has a model attached.\n",
      " |      This means saving a `tf.keras.Model` using `save_weights` and loading\n",
      " |      into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)\n",
      " |      will not match the `Model`'s variables. See the\n",
      " |      [guide to training checkpoints](\n",
      " |      https://www.tensorflow.org/guide/checkpoint) for details on\n",
      " |      the TensorFlow format.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String or PathLike, path to the file to save the weights\n",
      " |              to. When saving in TensorFlow format, this is the prefix used\n",
      " |              for checkpoint files (multiple files are generated). Note that\n",
      " |              the '.h5' suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`.\n",
      " |              Otherwise `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If `h5py` is not available when attempting to save in\n",
      " |              HDF5 format.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |          expand_nested: Whether to expand the nested models.\n",
      " |              If not provided, defaults to `False`.\n",
      " |          show_trainable: Whether to show if a layer is trainable.\n",
      " |              If not provided, defaults to `False`.\n",
      " |          layer_range: a list or tuple of 2 strings,\n",
      " |              which is the starting layer name and ending layer name\n",
      " |              (both inclusive) indicating the range of layers to be printed\n",
      " |              in summary. It also accepts regex patterns instead of exact\n",
      " |              name. In such case, start predicate will be the first element\n",
      " |              it matches to `layer_range[0]` and the end predicate will be\n",
      " |              the last element it matches to `layer_range[1]`.\n",
      " |              By default `None` which considers all layers of model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case\n",
      " |            of temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated\n",
      " |            across batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |            dict, with each key being the name of the metric. If `False`, they\n",
      " |            are returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in a\n",
      " |            `tf.function`.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
      " |      and `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments to be passed to\n",
      " |              *`json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
      " |      RuntimeError.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: announces that the method poses a security risk\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case\n",
      " |            of temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |            to a weight (float) to apply to the model's loss for the samples\n",
      " |            from this class during training. This can be useful to tell the\n",
      " |            model to \"pay more attention\" to samples from an under-represented\n",
      " |            class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated\n",
      " |            across batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |            dict, with each key being the name of the metric. If `False`, they\n",
      " |            are returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      For concrete examples of how to override this method see\n",
      " |      [Customizing what happens in fit](\n",
      " |      https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of\n",
      " |      training.  This typically includes the forward pass, loss calculation,\n",
      " |      backpropagation, and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
      " |      and `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a\n",
      " |      `keras.Model` has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become\n",
      " |      easier for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |          for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MyModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7fb2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_bulid import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e28843",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'to_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m build_model\u001b[39m.\u001b[39;49mto_device()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'to_device'"
     ]
    }
   ],
   "source": [
    "build_model.to_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68809973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import BayesianOptimization\n",
    "from model_bulid import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3103e94a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m turner \u001b[39m=\u001b[39m BayesianOptimization(build_model,\n\u001b[0;32m      2\u001b[0m     objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m     max_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     executions_per_trial\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     directory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmy_dir\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     project_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhelloworld\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras_tuner\\tuners\\bayesian.py:402\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[1;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    388\u001b[0m ):\n\u001b[0;32m    389\u001b[0m     oracle \u001b[39m=\u001b[39m BayesianOptimizationOracle(\n\u001b[0;32m    390\u001b[0m         objective\u001b[39m=\u001b[39mobjective,\n\u001b[0;32m    391\u001b[0m         max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m         max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[0;32m    401\u001b[0m     )\n\u001b[1;32m--> 402\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(oracle\u001b[39m=\u001b[39moracle, hypermodel\u001b[39m=\u001b[39mhypermodel, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:113\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[0;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m     )\n\u001b[1;32m--> 113\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    114\u001b[0m     oracle\u001b[39m=\u001b[39moracle,\n\u001b[0;32m    115\u001b[0m     hypermodel\u001b[39m=\u001b[39mhypermodel,\n\u001b[0;32m    116\u001b[0m     directory\u001b[39m=\u001b[39mdirectory,\n\u001b[0;32m    117\u001b[0m     project_name\u001b[39m=\u001b[39mproject_name,\n\u001b[0;32m    118\u001b[0m     logger\u001b[39m=\u001b[39mlogger,\n\u001b[0;32m    119\u001b[0m     overwrite\u001b[39m=\u001b[39moverwrite,\n\u001b[0;32m    120\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:135\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[0;32m    137\u001b[0m \u001b[39m# Run in distributed mode.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m dist_utils\u001b[39m.\u001b[39mis_chief_oracle():\n\u001b[0;32m    139\u001b[0m     \u001b[39m# Blocks forever.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:200\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[0;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[1;32m--> 200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_activate_all_conditions()\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:157\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m hp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_space()\n\u001b[0;32m    156\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[0;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m    160\u001b[0m     \u001b[39m# Update the recorded scopes.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\DeepLearning_HW\\model_bulid.py:79\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m# build the model\u001b[39;00m\n\u001b[0;32m     78\u001b[0m model \u001b[39m=\u001b[39m MyModel(activation_fn,hidden_node,init_weight,optimizer,regularization_coefficients,num_class\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m model\u001b[39m.\u001b[39;49mcompile(optimizer\u001b[39m=\u001b[39;49moptimizer,loss\u001b[39m=\u001b[39;49mloss_function,metrics \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\engine\\training.py:726\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss \u001b[39m=\u001b[39m loss\n\u001b[0;32m    725\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 726\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39;49mLossesContainer(\n\u001b[0;32m    727\u001b[0m         loss, loss_weights, output_names\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_names\n\u001b[0;32m    728\u001b[0m     )\n\u001b[0;32m    729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39mMetricsContainer(\n\u001b[0;32m    730\u001b[0m     metrics,\n\u001b[0;32m    731\u001b[0m     weighted_metrics,\n\u001b[0;32m    732\u001b[0m     output_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_names,\n\u001b[0;32m    733\u001b[0m     from_serialized\u001b[39m=\u001b[39mfrom_serialized,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_steps_per_execution(steps_per_execution \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\engine\\compile_utils.py:131\u001b[0m, in \u001b[0;36mLossesContainer.__init__\u001b[1;34m(self, losses, loss_weights, output_names, total_loss_mean)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_per_output_metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Per-output losses become metrics.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# Mean of the total loss.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_loss_mean \u001b[39m=\u001b[39m total_loss_mean \u001b[39mor\u001b[39;00m metrics_mod\u001b[39m.\u001b[39;49mMean(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_built \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\dtensor\\utils.py:144\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     instance\u001b[39m.\u001b[39m_mesh \u001b[39m=\u001b[39m mesh\n\u001b[1;32m--> 144\u001b[0m init_method(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\metrics\\base_metric.py:622\u001b[0m, in \u001b[0;36mMean.__init__\u001b[1;34m(self, name, dtype)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[39m@dtensor_utils\u001b[39m\u001b[39m.\u001b[39minject_mesh\n\u001b[0;32m    621\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 622\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    623\u001b[0m         reduction\u001b[39m=\u001b[39;49mmetrics_utils\u001b[39m.\u001b[39;49mReduction\u001b[39m.\u001b[39;49mWEIGHTED_MEAN,\n\u001b[0;32m    624\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    625\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\metrics\\base_metric.py:439\u001b[0m, in \u001b[0;36mReduce.__init__\u001b[1;34m(self, reduction, name, dtype)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(name\u001b[39m=\u001b[39mname, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m=\u001b[39m reduction\n\u001b[1;32m--> 439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\u001b[39m\"\u001b[39;49m\u001b[39mtotal\u001b[39;49m\u001b[39m\"\u001b[39;49m, initializer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzeros\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m reduction \u001b[39min\u001b[39;00m [\n\u001b[0;32m    441\u001b[0m     metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mSUM_OVER_BATCH_SIZE,\n\u001b[0;32m    442\u001b[0m     metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mWEIGHTED_MEAN,\n\u001b[0;32m    443\u001b[0m ]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\metrics\\base_metric.py:375\u001b[0m, in \u001b[0;36mMetric.add_weight\u001b[1;34m(self, name, shape, aggregation, synchronization, initializer, dtype)\u001b[0m\n\u001b[0;32m    372\u001b[0m     additional_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    374\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    376\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    377\u001b[0m         shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    378\u001b[0m         dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype,\n\u001b[0;32m    379\u001b[0m         trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    380\u001b[0m         initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    381\u001b[0m         collections\u001b[39m=\u001b[39m[],\n\u001b[0;32m    382\u001b[0m         synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    383\u001b[0m         aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    384\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39madditional_kwargs,\n\u001b[0;32m    385\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\engine\\base_layer.py:705\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    703\u001b[0m     getter \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(getter, layout\u001b[39m=\u001b[39mlayout)\n\u001b[1;32m--> 705\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[0;32m    706\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    707\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    708\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    709\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    710\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[0;32m    711\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    712\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    713\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    714\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    715\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    716\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    717\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    718\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[0;32m    719\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    720\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    721\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    723\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    724\u001b[0m     \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m     name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[: variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:489\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    480\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    481\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 489\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    490\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    491\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    492\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    493\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    496\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:134\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout)\u001b[0m\n\u001b[0;32m    127\u001b[0m     use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m layout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[39m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[39m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m tf1\u001b[39m.\u001b[39;49mVariable(\n\u001b[0;32m    135\u001b[0m         initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[0;32m    136\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    137\u001b[0m         trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    138\u001b[0m         caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    139\u001b[0m         dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[0;32m    140\u001b[0m         validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    141\u001b[0m         constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    142\u001b[0m         use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    143\u001b[0m         collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    144\u001b[0m         synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    145\u001b[0m         aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    146\u001b[0m         shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m dtensor\u001b[39m.\u001b[39mDVariable(\n\u001b[0;32m    150\u001b[0m         initial_value\u001b[39m=\u001b[39minit_val,\n\u001b[0;32m    151\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         shape\u001b[39m=\u001b[39mvariable_shape \u001b[39mif\u001b[39;00m variable_shape \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:264\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    263\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    265\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:209\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 209\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    210\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    211\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    212\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    213\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    214\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    215\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    216\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    217\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    218\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[0;32m    219\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    220\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    221\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    222\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    223\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    224\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:64\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3607\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3605\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3606\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3607\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:202\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    186\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    200\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    201\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2705\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2704\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2705\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2706\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2707\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2708\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   2709\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2710\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2711\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2712\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2713\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2714\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2715\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2716\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2717\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2718\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2719\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[0;32m   2720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2721\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2722\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2723\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2734\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2735\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1656\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope,\n\u001b[0;32m   1657\u001b[0m                         validate_shape\u001b[39m=\u001b[39mvalidate_shape)\n\u001b[0;32m   1658\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1659\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1660\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1661\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1662\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1663\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1664\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1665\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1666\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1667\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1668\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1669\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1670\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   1671\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   1672\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1812\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1811\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1812\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1813\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1814\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:171\u001b[0m, in \u001b[0;36mZeros.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39mcall_with_layout(\n\u001b[0;32m    169\u001b[0m         tf\u001b[39m.\u001b[39mzeros, layout, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mzeros(shape, dtype)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2971\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2971\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2972\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2973\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3032\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   3030\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shape\u001b[39m.\u001b[39m_shape_tuple():\n\u001b[0;32m   3031\u001b[0m     shape \u001b[39m=\u001b[39m reshape(shape, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])  \u001b[39m# Ensure it's a vector\u001b[39;00m\n\u001b[1;32m-> 3032\u001b[0m   output \u001b[39m=\u001b[39m fill(shape, constant(zero, dtype\u001b[39m=\u001b[39;49mdtype), name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   3033\u001b[0m \u001b[39massert\u001b[39;00m output\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39m==\u001b[39m dtype\n\u001b[0;32m   3034\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "turner = BayesianOptimization(build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691508f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.3_py_3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
